{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Corporate Sustainability"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 0 - Imports and Dependencies"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dependencies\n",
    "\n",
    "To run this notebook, please make sure you have the following packages installed:\n",
    "\n",
    "- `pandas`: For handling data in dataframes.\n",
    "- `datasets`: For loading datasets.\n",
    "- `spacy`: For natural language processing.\n",
    "- `scikit-learn`: For machine learning algorithms, vectorization, model evaluation, and pipelines.\n",
    "- `wordcloud`: For creating a visual interpretation of text analytics\n",
    "\n",
    "You can install these packages using the following command:\n",
    "\n",
    "```bash\n",
    "pip install pandas datasets spacy scikit-learn wordcloud\n",
    "\n",
    "\n",
    "python -m spacy download en_core_web_sm\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# General imports\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import spacy\n",
    "from textblob import TextBlob\n",
    "import plotly.express as px\n",
    "import seaborn as sns\n",
    "from collections import Counter\n",
    "from datasets import load_dataset\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.pipeline import Pipeline\n",
    "from wordcloud import WordCloud\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1 - Data Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data\n",
    "dataset = load_dataset('climatebert/environmental_claims')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display to show how the format of the dataset looks like\n",
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating a dataframe for each split\n",
    "\n",
    "env_claim_train = pd.DataFrame(dataset['train'])\n",
    "env_claim_test = pd.DataFrame(dataset['test'])\n",
    "env_claim_val = pd.DataFrame(dataset['validation'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define color codes\n",
    "class Colors:\n",
    "    OKBLUE = '\\033[94m'\n",
    "    OKCYAN = '\\033[96m'\n",
    "    OKGREEN = '\\033[92m'\n",
    "    ENDC = '\\033[0m'\n",
    "\n",
    "# Displaying the characteristics of the data\n",
    "print(Colors.OKGREEN + \"Training data\" + Colors.ENDC)\n",
    "print(f\"The shape of the training data is: {env_claim_train.shape}\")\n",
    "display(env_claim_train.head())\n",
    "display(env_claim_train.describe())\n",
    "\n",
    "print(Colors.OKBLUE + \"\\nTest data\" + Colors.ENDC)\n",
    "print(f\"The shape of the test data is: {env_claim_test.shape}\")\n",
    "display(env_claim_test.head())\n",
    "display(env_claim_test.describe())\n",
    "\n",
    "print(Colors.OKCYAN + \"\\nValidation data\" + Colors.ENDC)\n",
    "print(f\"The shape of the validation data is: {env_claim_val.shape}\")\n",
    "display(env_claim_val.head())\n",
    "display(env_claim_val.describe())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2- EDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Concatenate sets \n",
    "claim_dataset = pd.concat([env_claim_train, env_claim_test, env_claim_val], ignore_index = True)\n",
    "print(\"Number of claims in the dataset:\", claim_dataset.shape[0])    # observations\n",
    "print(\"Number of variables in the dataset:\", claim_dataset.shape[1]) # variables "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NaNs \n",
    "print(\"Number of NaNs:\")\n",
    "display(claim_dataset.isna().sum())\n",
    "\n",
    "# Duplicates\n",
    "print(\"Number of duplicates:\")\n",
    "display(claim_dataset.duplicated().sum())\n",
    "\n",
    "# Variable types\n",
    "print(\"Variable types:\")\n",
    "claim_dataset.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Word Count by Claim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Word count\n",
    "claim_dataset[\"word count\"] = claim_dataset[\"text\"].apply(lambda x: len(x.split()))\n",
    "print(\"The average number of words in each claim is equal to:\", round(claim_dataset[\"word count\"].mean(),0), \"words.\")\n",
    "\n",
    "# Graphical representation by class\n",
    "class_1_counts = claim_dataset[claim_dataset[\"label\"] == 1][\"word count\"]\n",
    "class_2_counts = claim_dataset[claim_dataset[\"label\"] == 0][\"word count\"]\n",
    "\n",
    "plt.hist(class_1_counts, bins = range(11, 39), alpha = 0.5, label = \"Environmental Claim\", color = \"#4958B5\")\n",
    "plt.hist(class_2_counts, bins = range(11, 39), alpha = 0.5, label = \"Non-environmental Claim\", color = \"#8DB8B7\")\n",
    "plt.xlabel(\"Word count\")\n",
    "plt.ylabel(\"Frequency\")\n",
    "plt.title(\"Number of Words in Each Claim by Class\")\n",
    "plt.legend(loc = \"upper right\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Claim Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load English language model\n",
    "sp = spacy.load('en_core_web_sm')\n",
    "\n",
    "# Apply the Spacy sp function to each row of the 'text' column\n",
    "claim_dataset[\"spacy object\"] = claim_dataset[\"text\"].apply(sp)\n",
    "\n",
    "# Filter stopwords, punctuation and spaces\n",
    "def filter_tokens(token):\n",
    "    return not token.is_stop and not token.is_punct and not token.is_space\n",
    "\n",
    "# Remove stopwords, punctuation, and whitespace from each Spacy object\n",
    "claim_dataset[\"filtered tokens\"] = claim_dataset[\"spacy object\"].apply(lambda doc: [token.text for token in doc if filter_tokens(token)])\n",
    "\n",
    "print(\"This is the first sentence before filtering:\", claim_dataset.iloc[0,0])\n",
    "print(\"\\nThis is the first sentence after filtering:\", claim_dataset.iloc[0,4])\n",
    "\n",
    "# Calculating new average value of words per claim\n",
    "number_words = [len(x) for x in claim_dataset[\"filtered tokens\"]]\n",
    "print(\"\\nThe average number of words per claim is now:\", round(np.mean(number_words),0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Environmental Claims versus Non-Environmental Claims"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mean \n",
    "print(\"Average number of words per claim by class:\")\n",
    "display(claim_dataset.groupby(\"label\").mean().round())\n",
    "\n",
    "# Median\n",
    "print(\"\\nMedian number of words per claim by class:\")\n",
    "display(claim_dataset.groupby(\"label\").median())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# WordCloud hue by class label\n",
    "\n",
    "# Join the strings in each list into a single string\n",
    "claim_dataset[\"joined tokens\"] = claim_dataset[\"filtered tokens\"].apply(lambda tokens: ' '.join(tokens))\n",
    "\n",
    "f, (ax1, ax2) = plt.subplots(1, 2, figsize=(24, 6))\n",
    "\n",
    "# For Environmental Claims\n",
    "text = \" \".join(word for word in claim_dataset[claim_dataset[\"label\"]==1][\"joined tokens\"])\n",
    "wordcloud = WordCloud( background_color = \"white\", colormap = \"Greens\").generate(text)\n",
    "\n",
    "ax1.imshow(wordcloud, interpolation = \"bilinear\")\n",
    "ax1.set(title = \"WordCloud of Environmental Claims\")\n",
    "ax1.axis(\"off\")\n",
    "\n",
    "# For Non-Environmental Claims\n",
    "text = \" \".join(word for word in claim_dataset[claim_dataset[\"label\"]==0][\"joined tokens\"])\n",
    "wordcloud = WordCloud(background_color = \"white\", colormap = \"Reds\").generate(text)\n",
    "\n",
    "ax2.imshow(wordcloud, interpolation='bilinear')\n",
    "ax2.set(title = \"WordCloud of Non-Environmental Claims\")\n",
    "ax2.axis(\"off\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Most frequent words for environmental claims\n",
    "top = Counter([item for sublist in claim_dataset[\"joined tokens\"][claim_dataset[\"label\"]==1] for item in str(sublist).split()])\n",
    "temp = pd.DataFrame(top.most_common(10))\n",
    "temp.columns = [\"Common Words\", \"Count\"]\n",
    "print(\"Most frequent words for environmental claims:\")\n",
    "display(temp.style.background_gradient(cmap = \"Greens\"))\n",
    "\n",
    "# Most frequent words for non-environmental claims\n",
    "top = Counter([item for sublist in claim_dataset[\"joined tokens\"][claim_dataset[\"label\"]==0] for item in str(sublist).split()])\n",
    "temp = pd.DataFrame(top.most_common(10))\n",
    "temp.columns = [\"Common Words\", \"Count\"]\n",
    "print(\"\\nMost frequent words for non-environmental claims:\")\n",
    "display(temp.style.background_gradient(cmap = \"Reds\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Studying Energy Claims using N-Grams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Need to finish this part"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "energy_df = claim_dataset[claim_dataset[\"joined tokens\"].str.contains(\"energy\")]\n",
    "print(\"In the original dataset, there are\", len(energy_df), \"claims containing the word 'energy'.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function calculating most frequent N-Grams given corpus, top number of n-grams and n-grams\n",
    "def top_n_ngram(energy_corpus, n = None, ngram = 3):\n",
    "    vec = CountVectorizer(ngram_range = (ngram,ngram)).fit(energy_corpus)\n",
    "    words_bag = vec.transform(energy_corpus) # Have the count of  all the words for each claim\n",
    "    sum_words = words_bag.sum(axis =0)       # Calculates the count of all the word in the whole claim\n",
    "    words_freq = [(word,sum_words[0,idx]) for word,idx in vec.vocabulary_.items()]\n",
    "    words_freq = sorted(words_freq,key = lambda x:x[1],reverse = True)\n",
    "    return words_freq[:n]\n",
    "\n",
    "\n",
    "# Plotting the results\n",
    "pop_words = top_n_ngram(energy_df[\"joined tokens\"], 29,3)     # Call function\n",
    "pop_energy = [t for t in pop_words if \"energy\" in t[0]]       # Select N-Grams having 'energy' in text\n",
    "df_n = pd.DataFrame(pop_energy, columns = [\"Text\", \"count\"])\n",
    "colors = np.where(energy_df[\"label\"] == 1, 'g', 'r')                           # Assign color based on label value\n",
    "plt.figure(figsize = (20,5))\n",
    "df_n.groupby(\"Text\").sum()['count'].sort_values(ascending=False).plot(\n",
    "kind = \"bar\", title = \"20 Most Frequent 3-grams Containing Word 'Energy'\", ylabel = \"Count\", color = colors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[t for t in pop_words if \"renewable energy sources\" in t[0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[t for t in energy_df[\"joined tokens\"] if \"renewable energy sources\" in t]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Declaring the train and test datasets for X and y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, y_train = env_claim_train['text'], env_claim_train['label']\n",
    "X_test, y_test = env_claim_test['text'], env_claim_test['label']\n",
    "X_val, y_val = env_claim_val['text'], env_claim_test['label']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exploring Labelled Data and Defining Base Rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train Set\n",
    "print(Colors.OKGREEN + \"Train set per class:\" + Colors.ENDC)\n",
    "display(y_train.value_counts())\n",
    "      \n",
    "\n",
    "# Test Set \n",
    "print(Colors.OKBLUE + \"\\nTest set per class:\" + Colors.ENDC)\n",
    "display(y_test.value_counts())\n",
    "\n",
    "# Validation Set\n",
    "print(Colors.OKCYAN + \"\\nValidation set per class:\" + Colors.ENDC)\n",
    "display(y_val.value_counts())\n",
    "\n",
    "\n",
    "# Graphical representation\n",
    "outcome_variable = pd.concat([y_train, y_test, y_val])\n",
    "outcome_variable.value_counts().plot.bar(color = [\"#4958B5\", \"#8DB8B7\"], grid = False)\n",
    "plt.ylabel(\"Number of observations\")\n",
    "plt.xlabel(\"Class\")\n",
    "plt.title(\"Number of Observations per Class\")\n",
    "plt.xticks(rotation = 0)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Base rate\n",
    "base_rate = round(len(outcome_variable[outcome_variable == 0]) / len (outcome_variable), 4)\n",
    "print(f'The base rate is: {base_rate*100:0.2f}%')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Balancing Labelled Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get indices of \"0\" outcomes in the training set\n",
    "train_zeros_idx = pd.Series(y_train[y_train == 0].index)\n",
    "\n",
    "# Randomly select a balanced number of \"0\" outcomes\n",
    "train_zeros_sample_idx = train_zeros_idx.sample(n = sum(y_train == 1), random_state = 7)\n",
    "\n",
    "# Use the sampled indices to get the final balanced training set\n",
    "X_train_bal = pd.concat([X_train[y_train == 1], X_train[train_zeros_sample_idx]])\n",
    "y_train_bal = pd.concat([y_train[y_train == 1], y_train[train_zeros_sample_idx]])\n",
    "\n",
    "\n",
    "# Get indices of \"0\" outcomes in the test set\n",
    "test_zeros_idx = pd.Series(y_test[y_test == 0].index)\n",
    "\n",
    "# Randomly select a balanced number of \"0\" outcomes\n",
    "test_zeros_sample_idx = test_zeros_idx.sample(n = sum(y_test == 1), random_state = 7)\n",
    "\n",
    "# Use the sampled indices to get the final balanced test set\n",
    "X_test_bal = pd.concat([X_test[y_test == 1], X_test[test_zeros_sample_idx]])\n",
    "y_test_bal = pd.concat([y_test[y_test == 1], y_test[test_zeros_sample_idx]])\n",
    "\n",
    "\n",
    "# Get indices of \"0\" outcomes in the validation set\n",
    "val_zeros_idx = pd.Series(y_val[y_val == 0].index)\n",
    "\n",
    "# Randomly select a balanced number of \"0\" outcomes\n",
    "val_zeros_sample_idx = val_zeros_idx.sample(n = sum(y_val == 1), random_state = 7)\n",
    "\n",
    "# Use the sampled indices to get the final balanced validation set\n",
    "X_val_bal = pd.concat([X_val[y_val == 1], X_val[val_zeros_sample_idx]])\n",
    "y_val_bal = pd.concat([y_val[y_val == 1], y_val[val_zeros_sample_idx]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Number of observations per class after balancing the classes:\\n\")\n",
    "\n",
    "# Train Set\n",
    "print(Colors.OKGREEN + \"Train set per class\" + Colors.ENDC)\n",
    "display(y_train_bal.value_counts())\n",
    "      \n",
    "\n",
    "# Test Set \n",
    "print(Colors.OKBLUE + \"\\nTest set per class\" + Colors.ENDC)\n",
    "display(y_test_bal.value_counts())\n",
    "\n",
    "# Validation Set\n",
    "print(Colors.OKCYAN + \"\\nValidation set per class\" + Colors.ENDC)\n",
    "display(y_val_bal.value_counts())\n",
    "\n",
    "print(\"\\nThe new balanced dataset contains\", len(y_train_bal + y_test_bal + y_val_bal) , \"observations.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3- "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Text Classification using TF-IDF Vectorization and Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a spaCy tokenizer\n",
    "nlp = spacy.load('en_core_web_sm', disable=['parser', 'ner'])\n",
    "def spacy_tokenizer(text):\n",
    "    return [tok.lemma_.lower().strip() for tok in nlp(text) if tok.is_alpha and not tok.is_stop]\n",
    "\n",
    "# Create a TfidfVectorizer with the spaCy tokenizer\n",
    "vectorizer = TfidfVectorizer(tokenizer=spacy_tokenizer, ngram_range=(1, 2), max_df=0.85, min_df=2)\n",
    "\n",
    "# Create a logistic regression classifier\n",
    "clf = LogisticRegression(solver='liblinear')\n",
    "\n",
    "# Create a pipeline with the vectorizer and classifier\n",
    "pipe = Pipeline([('vectorizer', vectorizer), ('classifier', clf)])\n",
    "\n",
    "# Train the model\n",
    "pipe.fit(X_train, y_train)\n",
    "\n",
    "# Test the model\n",
    "y_pred = pipe.predict(X_test)\n",
    "\n",
    "# Calculate accuracy and print the classification report\n",
    "accuracy = accuracy_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Accuracy: {accuracy}\")\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualizing Word Importance with Word Clouds for Each Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_word_cloud(classifier, vectorizer, class_index, class_label):\n",
    "    # Get the feature names (words) from the vectorizer\n",
    "    words = vectorizer.get_feature_names_out()\n",
    "\n",
    "    # Get the coefficients (importance) of the words for the given class\n",
    "    word_importance = classifier.coef_[0]\n",
    "\n",
    "    # Create a dictionary with the words and their importance\n",
    "    if class_index == 0:\n",
    "        colormap = \"Reds\"\n",
    "        word_importance_dict = {words[i]: -word_importance[i] for i in range(len(words)) if word_importance[i] < 0}\n",
    "    else:\n",
    "        word_importance_dict = {words[i]: word_importance[i] for i in range(len(words)) if word_importance[i] > 0}\n",
    "        colormap = \"Greens\"\n",
    "\n",
    "    # Create a WordCloud object\n",
    "    wc = WordCloud(width=800, height=400, background_color=\"white\", colormap=colormap)\n",
    "\n",
    "    # Generate the word cloud using the word importance dictionary\n",
    "    wc.generate_from_frequencies(word_importance_dict)\n",
    "\n",
    "    # Plot the word cloud\n",
    "    plt.figure(figsize=(12, 6))\n",
    "    plt.imshow(wc, interpolation=\"bilinear\")\n",
    "    plt.axis(\"off\")\n",
    "    plt.title(f\"Word Cloud for {class_label}\", fontsize=20)\n",
    "    plt.show()\n",
    "\n",
    "# Create the word clouds for each class\n",
    "plot_word_cloud(clf, vectorizer, 0, \"Greenwashing Companies\")\n",
    "plot_word_cloud(clf, vectorizer, 1, \"Genuine Green impact Companies\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Environment description"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext watermark\n",
    "%watermark -v -p pandas,numpy,sklearn,datasets,spacy,wordcloud"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
